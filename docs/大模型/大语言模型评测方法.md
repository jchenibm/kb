Parent：[[大语言模型评测]]
# 大语言模型评测方法

| 评测方法 | 说明 |
|-|-|  
| 人工评测 | 请专业人士针对不同维度给出主观打分 |
| 自动化评测 | 使用正确性、相似度等自动评价指标 |
| 对话式评测 | 让模型与评估者进行多轮互动|
| 指定任务评测 | 让模型完成特定的语言任务并评分 |
| 对比式评测 | 同时测试多个模型,比较其优劣 |

具体来说:

- 人工评测可以设计针对性的评测维度,但耗时费力,不容易大规模。

- 自动化评测高效,可以大规模评测,但评价维度有限,主观性弱。

- 对话式评测可以考察模型的对话能力,但评价规范难定义。

- 指定任务评测可以直观考察特定能力,但任务设置具有主观性。

- 对比式评测可以明确不同模型之间的差距,但需要关注样本代表性。